{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Write2Audiobook","text":"<p>Write2Audiobook is a powerful tool that converts EPUB, TXT, PPT, and DOCX documents into engaging audiobooks directly from the command-line. This tool is perfect for making reading more accessible for people with visual impairments and for those who simply prefer listening on the go.</p> <p>To see Write2Audiobook in action, check out the Quick start guide. Then go to the User guide to learn more.</p>"},{"location":"quick-start/","title":"Quick start guide","text":"<p>Follow this tutorial to learn how to use Write2Audiobook.</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, download and install the required files.</p> <p>Learn more about downloading the scripts from GitHub and installing the required packages.</p>"},{"location":"quick-start/#convert-a-text-based-file-to-an-audiobook","title":"Convert a text-based file to an audiobook","text":"<ol> <li> <p>In your terminal, go to the Write2Audiobook project's root directory.</p> <pre><code>cd write2audiobook\n</code></pre> </li> <li> <p>Run one of the scripts to convert a text-based file to an audiobook:     To convert an Ebook (EPUB) to an audiobook:</p> <pre><code>python3 ebook2audio.py book.epub\n</code></pre> <p>To convert a plain text file to an audiobook:</p> <pre><code>python3 txt2audio.py text.txt\n</code></pre> <p>To convert a PowerPoint presentation (PPTX) to an audiobook:</p> <pre><code>python3 pptx2audio.py presentation.pptx\n</code></pre> <p>To convert a Word document (DOCX) to an audiobook:</p> <pre><code>python3 docx2audio.py document.docx\n</code></pre> </li> </ol>"},{"location":"quick-start/#play-your-audiobook","title":"Play your audiobook","text":"<p>Write2Audio saves your audiobook as an audio file in the current directory. It will have the same name as the converted file.</p> <p></p> <p>You can listen to your audiobook with any program that can open MP3 or M4B files, like VLC.</p>"},{"location":"about/contributing/","title":"Contributing","text":"<p>We welcome contributions!</p>"},{"location":"about/contributing/#before-you-begin","title":"Before you begin","text":"<p>Browse the open issues. Leave a comment in the issue before you start working on it. This lets the maintainers assign the issue to you and therefore prevent duplicate work from different contributors.</p> <p>If you want to suggest a change but can't find it in the open issues list, open a new issue. A maintainer will discuss your changes with you and the rest of the contributor community. If you want to make the change, a maintainer will assign the issue to you.</p>"},{"location":"about/contributing/#how-you-can-contribute","title":"How you can contribute","text":"<p>To contribute, fork the repository and submit a pull request. A maintainer will review your submitted changes. If the maintainer approves the changes, they will merge the changes into the main branch of the repository.</p> <p>Learn more about contributing to a project through forking.</p> <p>Feel free to contact us on GitHub if you have any questions, suggestions, or feedback.</p>"},{"location":"about/license/","title":"License","text":"<p>Copyright information for the Write2Audiobook project.</p>"},{"location":"about/license/#included-projects","title":"Included projects","text":"<ul> <li>Material theme - View license.</li> <li>MkDocs site generator - View license</li> </ul> <p>Many thanks to the authors and contributors of those wonderful projects.</p>"},{"location":"about/license/#write2audiobook-license-mit","title":"Write2Audiobook license (MIT)","text":"<p>Copyright (c) 2023 De Angelis Domenico Francesco</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"reference/","title":"Reference","text":"<p>This section describes the modules used in the Write2Audiobook project.</p> <p>See the pages to the left to learn more about each module.</p>"},{"location":"reference/backend-audio/","title":"backend_audio","text":"<p>This page describes the functions in the <code>backend_audio</code> module.</p>"},{"location":"reference/backend-audio/#backend_audio.ffmetadata_generator","title":"<code>backend_audio.ffmetadata_generator</code>","text":""},{"location":"reference/backend-audio/#backend_audio.ffmetadata_generator.generate_ffmetadata","title":"<code>generate_ffmetadata(input_audio_paths, chapter_titles=None, author=None, title=None)</code>","text":"<p>Generate metadata in ffmpeg format.</p> <p>Parameters:</p> <ul> <li> <code>input_audio_paths</code>               (<code>list</code>)           \u2013            <p>List[str] - path of audiable files</p> </li> <li> <code>chapter_titles</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List[str] - name of chapters defined on each files</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>metadata</code> (              <code>str</code> )          \u2013            <p>str</p> </li> </ul> Source code in <code>backend_audio/ffmetadata_generator.py</code> <pre><code>def generate_ffmetadata(input_audio_paths:list,\n                        chapter_titles:list=None,\n                        author:str=None,\n                        title:str=None) -&gt; str:\n    \"\"\"Generate metadata in ffmpeg format.\n\n    Arguments:\n        input_audio_paths: List[str] - path of audiable files\n        chapter_titles:    List[str] - name of chapters defined on each files\n\n    Returns:\n        metadata: str\n    \"\"\"\n    starttimes=__get_track_times(input_audio_paths)\n    if chapter_titles is None:\n        chapter_titles = []\n    # https://ffmpeg.org/ffmpeg-formats.html#Metadata-1\n    # \"If the timebase is missing then start/end times are assumed to be in \ud835\uddfb\ud835\uddee\ud835\uddfb\ud835\uddfc\ud835\ude00\ud835\uddf2\ud835\uddf0\ud835\uddfc\ud835\uddfb\ud835\uddf1\ud835\ude00.\"\n    # \"chapter start and end times in form \u2018START=num\u2019, \u2018END=num\u2019, where num is a \ud835\uddfd\ud835\uddfc\ud835\ude00\ud835\uddf6\ud835\ude01\ud835\uddf6\ud835\ude03\ud835\uddf2 \ud835\uddf6\ud835\uddfb\ud835\ude01\ud835\uddf2\ud835\uddf4\ud835\uddf2\ud835\uddff.\"\n    metadata = __get_ffmetadata1(author=author, title=title)\n    last_end = 0\n    for idx, start_time in enumerate(starttimes):\n        metadata += f\"[CHAPTER]\\nSTART={last_end}\\nEND={start_time}\\n\"\n        if len(chapter_titles) == 0:\n            metadata += f\"title=c{idx}\\n\"\n        else:\n            metadata += f\"title={chapter_titles[idx]}\\n\"\n        last_end = start_time\n    return metadata\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b","title":"<code>backend_audio.m4b</code>","text":"<p>Module aim to generate audio and the file result in M4B</p>"},{"location":"reference/backend-audio/#backend_audio.m4b.close_edge_tts","title":"<code>close_edge_tts()</code>","text":"<p>Need to close the async io process.</p> Source code in <code>backend_audio/m4b.py</code> <pre><code>def close_edge_tts() -&gt; None:\n    \"\"\"Need to close the async io process.\"\"\"\n    global loop #pylint: disable=W0603,W0602\n    if loop:\n        loop.close()\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.generate_audio","title":"<code>generate_audio(text_in, out_mp3_path, *, lang='it', backend='PYTTS')</code>","text":"<p>Generating audio using tts apis. Arguments:     text_in: The text used to generate the TTS.     out_mp3_path: The path to save the result MP3 file.     lang: The desired language abbreviation.     backend: The string name of the TTS engine. Returns:     True if the function succesfully saves the MP3 file.</p> Source code in <code>backend_audio/m4b.py</code> <pre><code>def generate_audio(text_in:str, out_mp3_path:str, *,\n                   lang:str=\"it\", backend:str=\"PYTTS\") -&gt; bool:\n    \"\"\"Generating audio using tts apis.\n    Arguments:\n        text_in: The text used to generate the TTS.\n        out_mp3_path: The path to save the result MP3 file.\n        lang: The desired language abbreviation.\n        backend: The string name of the TTS engine.\n    Returns:\n        True if the function succesfully saves the MP3 file.\n    \"\"\"\n    ret_val = True\n    text_in = text_in.strip()\n    if len(text_in) == 0:\n        return False\n    if backend == \"GTTS\":\n        ret_val = generate_audio_gtts(text_in, out_mp3_path, lang=lang)\n    elif backend == \"PYTTS\":\n        ret_val = generate_audio_pytts(text_in, out_mp3_path, lang=lang)\n    elif backend == \"EDGE_TTS\":\n        loop_audio = asyncio.get_event_loop_policy().get_event_loop()\n        loop_audio.run_until_complete(generate_audio_edge_tts(text_in, out_mp3_path,\n                                                              lang=lang, voice=voice_edge))\n    return ret_val\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.generate_audio_edge_tts","title":"<code>generate_audio_edge_tts(text_in, out_mp3_path, *, lang='it', voice)</code>  <code>async</code>","text":"<p>Generate audio with EDGE-TTS starting from text_in string and save it in out_mp3_path path.</p> <p>Parameters:</p> <ul> <li> <code>text_in</code>               (<code>str</code>)           \u2013            <p>The text used to generate the TTS.</p> </li> <li> <code>out_mp3_path</code>               (<code>str</code>)           \u2013            <p>The path to save the result MP3 file.</p> </li> <li> <code>lang</code>               (<code>str</code>, default:                   <code>'it'</code> )           \u2013            <p>The desired language abbreviation.</p> </li> <li> <code>voice</code>               (<code>str</code>)           \u2013            <p>The TTS engine voice ID.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>True if the function succesfully saves the MP3 file.</p> </li> </ul> Source code in <code>backend_audio/m4b.py</code> <pre><code>async def generate_audio_edge_tts(text_in:str,\n                                  out_mp3_path:str, *,\n                                  lang:str=\"it\", # pylint: disable=W0613\n                                  voice:str) -&gt; bool:\n    \"\"\"Generate audio with EDGE-TTS starting from text_in string\n    and save it in out_mp3_path path.\n\n    Arguments:\n        text_in: The text used to generate the TTS.\n        out_mp3_path: The path to save the result MP3 file.\n        lang: The desired language abbreviation.\n        voice: The TTS engine voice ID.\n\n    Returns:\n        True if the function succesfully saves the MP3 file.\n    \"\"\"\n    com = edge_tts.Communicate(text_in, voice)\n    await com.save(out_mp3_path)\n    return True\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.generate_audio_gtts","title":"<code>generate_audio_gtts(text_in, out_mp3_path, *, lang='it')</code>","text":"<p>Generate audio using GTTS apis.</p> <p>Parameters:</p> <ul> <li> <code>text_in</code>               (<code>str</code>)           \u2013            <p>The text used to generate the TTS.</p> </li> <li> <code>out_mp3_path</code>               (<code>str</code>)           \u2013            <p>The path to save the result MP3 file.</p> </li> <li> <code>lang</code>               (<code>str</code>, default:                   <code>'it'</code> )           \u2013            <p>The desired language abbreviation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>True if the function succesfully saves the MP3 file.</p> </li> </ul> Source code in <code>backend_audio/m4b.py</code> <pre><code>def generate_audio_gtts(text_in:str, out_mp3_path:str, *, lang:str=\"it\") -&gt; bool:\n    \"\"\"Generate audio using GTTS apis.\n\n    Arguments:\n        text_in: The text used to generate the TTS.\n        out_mp3_path: The path to save the result MP3 file.\n        lang: The desired language abbreviation.\n\n    Returns:\n        True if the function succesfully saves the MP3 file.\n    \"\"\"\n    chunks = __split_text_into_chunks(text_in)\n    if len(chunks)&gt;1:\n        __sub_audio(__save_tts_audio_gtts, out_mp3_path, chunks, lang)\n    else:\n        return __save_tts_audio_gtts(text_in, out_mp3_path, lang)\n    return True\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.generate_audio_pytts","title":"<code>generate_audio_pytts(text_in, out_mp3_path, *, lang='it')</code>","text":"<p>Generate audio using PYTTS apis.</p> <p>Parameters:</p> <ul> <li> <code>text_in</code>               (<code>str</code>)           \u2013            <p>The text used to generate the TTS.</p> </li> <li> <code>out_mp3_path</code>               (<code>str</code>)           \u2013            <p>The path to save the result MP3 file.</p> </li> <li> <code>lang</code>               (<code>str</code>, default:                   <code>'it'</code> )           \u2013            <p>The desired language abbreviation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>True if the function succesfully saves the MP3 file.</p> </li> </ul> Source code in <code>backend_audio/m4b.py</code> <pre><code>def generate_audio_pytts(text_in:str, out_mp3_path:str, *, lang:str=\"it\") -&gt; bool:\n    \"\"\"Generate audio using PYTTS apis.\n\n    Arguments:\n        text_in: The text used to generate the TTS.\n        out_mp3_path: The path to save the result MP3 file.\n        lang: The desired language abbreviation.\n\n    Returns:\n        True if the function succesfully saves the MP3 file.\n    \"\"\"\n    if engine_ptts.getProperty(\"voice\") != lang:\n        engine_ptts.setProperty(\"voice\", LANGUAGE_DICT_PYTTS[lang])\n    engine_ptts.save_to_file(text_in, out_mp3_path)\n    engine_ptts.runAndWait()\n    return True\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.generate_m4b","title":"<code>generate_m4b(output_path, chapter_paths, ffmetadata)</code>","text":"<p>Generate the final audiobook starting from MP3s and METADATAs.</p> <p>Parameters:</p> <ul> <li> <code>output_path</code>               (<code>str</code>)           \u2013            <p>The path to save the final audiobook.</p> </li> <li> <code>chapter_paths</code>               (<code>List[str]</code>)           \u2013            <p>The paths where each chapter was saved.</p> </li> <li> <code>ffmetadata</code>               (<code>str</code>)           \u2013            <p>The ffmetadata file content.</p> </li> </ul> Source code in <code>backend_audio/m4b.py</code> <pre><code>def generate_m4b(output_path: str, chapter_paths: List[str], ffmetadata: str) -&gt; None:\n    \"\"\"Generate the final audiobook starting from MP3s and METADATAs.\n\n    Arguments:\n        output_path: The path to save the final audiobook.\n        chapter_paths: The paths where each chapter was saved.\n        ffmetadata: The ffmetadata file content.\n    \"\"\"\n    inputs_mp3 = [ffmpeg.input(cp) for cp in chapter_paths]\n    joined = ffmpeg.concat(*inputs_mp3, v=0, a=1)\n    # Build FFmpeg command for setting metadata\n    out = ffmpeg.output(joined, output_path, f='mp4', map_metadata=0, audio_bitrate=BIT_RATE_HUMAN)\n    ffmetadata_path = \"ffmetada\"\n    with open(ffmetadata_path, \"w\", encoding=\"UTF-8\") as file_ffmetadata:\n        file_ffmetadata.write(ffmetadata)\n    out = out.global_args('-f', 'ffmetadata', '-i', ffmetadata_path)\n    try:\n        ffmpeg.run(out)\n    except ffmpeg.Error as e:\n        logger.error(e.stderr.decode())\n        raise e\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.get_back_end_tts","title":"<code>get_back_end_tts()</code>","text":"<p>Get the TTS engine for the system's operating system.</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The string name of the engine used for the caller's operating system.</p> </li> </ul> Source code in <code>backend_audio/m4b.py</code> <pre><code>def get_back_end_tts() -&gt; str:\n    \"\"\"Get the TTS engine for the system's operating system.\n\n    Returns:\n        The string name of the engine used for the caller's operating system.\n    \"\"\"\n    os_engine_map = {\n        \"win32\": \"EDGE_TTS\",\n        \"cygwin\": \"EDGE_TTS\",\n        \"darwin\": \"GTTS\"\n    }\n    return os_engine_map.get(sys.platform, \"PYTTS\")\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.get_voices_edge_tts","title":"<code>get_voices_edge_tts(lang=LANGUAGE_DICT['it'])</code>  <code>async</code>","text":"<p>get FEMALE voices in target language from EDGE-TTS.</p> <p>Parameters:</p> <ul> <li> <code>lang</code>               (<code>str</code>, default:                   <code>LANGUAGE_DICT['it']</code> )           \u2013            <p>The desired language abbreviation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ret</code> (              <code>List[Dict[str, Any]]</code> )          \u2013            <p>A list of matching voice mappings based on lang.</p> </li> </ul> Source code in <code>backend_audio/m4b.py</code> <pre><code>async def get_voices_edge_tts(lang:str=LANGUAGE_DICT[\"it\"]) -&gt; List[Dict[str, Any]]:\n    \"\"\"get FEMALE voices in target language from EDGE-TTS.\n\n    Arguments:\n        lang: The desired language abbreviation.\n\n    Returns:\n        ret: A list of matching voice mappings based on lang.\n    \"\"\"\n    try:\n        vs = await edge_tts.VoicesManager.create()\n        ret = vs.find(Gender=\"Female\", Language=lang)\n    except Exception: #TODO add a best exception handling #pylint: disable=W0511,W0718\n        ret = []\n    return ret\n</code></pre>"},{"location":"reference/backend-audio/#backend_audio.m4b.init","title":"<code>init(backend)</code>","text":"<p>Init back end code per text-to-speech SUPPORTED: EDGE_TTS, PYTTS, GTTS.</p> <p>Parameters:</p> <ul> <li> <code>backend</code>               (<code>str</code>)           \u2013            <p>The string name of the TTS engine.</p> </li> </ul> Source code in <code>backend_audio/m4b.py</code> <pre><code>def init(backend:str) -&gt; None:\n    \"\"\"Init back end code per text-to-speech\n    SUPPORTED: EDGE_TTS, PYTTS, GTTS.\n\n    Arguments:\n        backend: The string name of the TTS engine.\n    \"\"\"\n    global engine_ptts #pylint: disable=W0603\n    global voice_edge  #pylint: disable=W0603\n    global loop        #pylint: disable=W0603\n    if backend == \"PYTTS\":\n        engine_ptts = pyttsx3.init()\n        engine_ptts.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n    elif backend == \"EDGE_TTS\":\n        asyncio.set_event_loop(asyncio.ProactorEventLoop())\n        loop = asyncio.get_event_loop_policy().get_event_loop()\n        voices = loop.run_until_complete(get_voices_edge_tts(lang=\"it\"))\n        voice_edge = voices[0][\"Name\"]\n</code></pre>"},{"location":"reference/docx2audio/","title":"docx2audio","text":"<p>This page describes the functions in the <code>docx2audio</code> script.</p>"},{"location":"reference/docx2audio/#docx2audio","title":"<code>docx2audio</code>","text":"<p>file: docx2audio.py</p> <p>description: Convert your docx file to audiobook in MP3 format.</p> Usage example <p><code>python docx2audio.py document.docx</code></p>"},{"location":"reference/docx2audio/#docx2audio.extract_chapters","title":"<code>extract_chapters(doc, style_start_chapter_name=TITLE_TOKENS)</code>","text":"<p>Extract chapters as list of paragraphs and table, the chapter are structured as Title (with style like Heading1 and Title) and corpus (other styles).</p> <p>Parameters:</p> <ul> <li> <code>doc</code>               (<code>Document</code>)           \u2013            <p>The main Word document item.</p> </li> <li> <code>style_start_chapter_name</code>               (<code>Tuple[str]</code>, default:                   <code>TITLE_TOKENS</code> )           \u2013            <p>Possible identifiers for titles in the Word document.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[Union[Paragraph, Table]]</code>           \u2013            <p>A list of Paragraph or Table objects.</p> </li> </ul> Source code in <code>docx2audio.py</code> <pre><code>def extract_chapters(doc:Document,\n                     style_start_chapter_name:Tuple[str] = TITLE_TOKENS\n                     ) -&gt; List[Union[Paragraph, Table]]:\n    \"\"\"Extract chapters as list of paragraphs and table, the chapter are structured as\n    Title (with style like Heading1 and Title) and corpus (other styles).\n\n    Arguments:\n        doc: The main Word document item.\n        style_start_chapter_name: Possible identifiers for titles in the Word document.\n\n    Returns:\n        A list of Paragraph or Table objects.\n    \"\"\"\n    temp_chapters: List[List[Union[Paragraph, Table]]] = []\n    temp:List[Union[Paragraph, Table]] = []\n    for block in iter_block_items(doc):\n        if isinstance(block, Paragraph):\n            if block.style.name in style_start_chapter_name:\n                if len(temp) &gt; 1:\n                    temp_chapters.append(temp)\n                temp = []\n            if len(block.text) == 0:\n                continue\n        temp.append(block)\n    return [i for i in temp_chapters if len(i)&gt;0]\n</code></pre>"},{"location":"reference/docx2audio/#docx2audio.get_text_from_chapter","title":"<code>get_text_from_chapter(chapter_doc, language=LANGUAGE)</code>","text":"<p>Generate an intermediate representation in textual version, starting from docx format to pure textual, adding sugar context information.</p> <p>Parameters:</p> <ul> <li> <code>chapter_doc</code>               (<code>List[Union[Paragraph, Table]]</code>)           \u2013            <p>A list of Paragraphs and Tables.</p> </li> <li> <code>language</code>               (<code>str</code>, default:                   <code>LANGUAGE</code> )           \u2013            <p>The desired language abbreviation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[str, str]</code>           \u2013            <p>A tuple of the object's title and its text content.</p> </li> </ul> Source code in <code>docx2audio.py</code> <pre><code>def get_text_from_chapter(chapter_doc:List[Union[Paragraph, Table]],\n                          language:str=LANGUAGE) -&gt; Tuple[str, str]:\n    \"\"\"Generate an intermediate representation in textual version,\n    starting from docx format to pure textual, adding sugar context information.\n\n    Arguments:\n        chapter_doc: A list of Paragraphs and Tables.\n        language: The desired language abbreviation.\n\n    Returns:\n        A tuple of the object's title and its text content.\n    \"\"\"\n    title_str = chapter_doc[0].text\n    text = f\"{TITLE_KEYWORD[language]}: {title_str}.\\n\"\n    idx_list = 0\n    for block in chapter_doc[1:]:\n        if isinstance(block, Paragraph):\n            temp_text, idx_list = get_text_from_paragraph(block, language, idx_list)\n            text += temp_text\n        elif isinstance(block, Table):\n            text += get_text_from_table(block, language)\n    return text, title_str\n</code></pre>"},{"location":"reference/docx2audio/#docx2audio.get_text_from_paragraph","title":"<code>get_text_from_paragraph(block, language, idx_list)</code>","text":"<p>Generate text starting from Paragraph object Arguments:     block (Table)     language (str)     idx_list (int) Return:     str: table text     idx_list</p> Source code in <code>docx2audio.py</code> <pre><code>def get_text_from_paragraph(block: Paragraph, language:str,\n                            idx_list:int) -&gt; Tuple[str, int]:\n    \"\"\"Generate text starting from Paragraph object\n    Arguments:\n        block (Table)\n        language (str)\n        idx_list (int)\n    Return:\n        str: table text\n        idx_list\n    \"\"\"\n    text = \"\"\n    if block.style.name == LIST_ITEM_TOKEN:\n        text += f\"\\t{idx_list}: {block.text}.\\n\"\n        idx_list += 1\n        return text, idx_list\n    idx_list = 0\n    if block.style.name == CHAPTER_TOKEN:\n        text += f\"\\n.\\n{CHAPTER_KEYWORD[language]}: \"\n    text += f\"{block.text}\\n\"\n    return text, idx_list\n</code></pre>"},{"location":"reference/docx2audio/#docx2audio.get_text_from_table","title":"<code>get_text_from_table(block, language)</code>","text":"<p>Generate text starting from Table object Arguments:     block (Table)     language (str) Return:     str: table text</p> Source code in <code>docx2audio.py</code> <pre><code>def get_text_from_table(block: Table, language:str) -&gt; str: #pylint: disable=W0613\n    \"\"\"Generate text starting from Table object\n    Arguments:\n        block (Table)\n        language (str)\n    Return:\n        str: table text\n    \"\"\"\n    text = \"\"\n    for row in block.rows:\n        row_data = []\n        for cell in row.cells:\n            for paragraph in cell.paragraphs:\n                row_data.append(paragraph.text)\n        text += \"{}\\n\".format('\\t'.join(row_data))\n    return text\n</code></pre>"},{"location":"reference/docx2audio/#docx2audio.iter_block_items","title":"<code>iter_block_items(parent)</code>","text":"<p>Generate a reference to each paragraph and table child within parent, in document order. Each returned value is an instance of either Table or Paragraph. parent would most commonly be a reference to a main Document object, but also works for a _Cell object, which itself can contain paragraphs and tables.</p> <p>Parameters:</p> <ul> <li> <code>parent</code>               (<code>Union[Document, _Cell, _Row]</code>)           \u2013            <p>The main Word document object, or an individual <code>_Cell</code> object.</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>Union[Paragraph, Table]</code>           \u2013            <p>A Paragraph or Table object.</p> </li> </ul> Source code in <code>docx2audio.py</code> <pre><code>def iter_block_items(\n    parent:Union[Document, _Cell, _Row]\n) -&gt; Generator[Union[Paragraph, Table], None, None]:\n    \"\"\"\n    Generate a reference to each paragraph and table child within *parent*,\n    in document order. Each returned value is an instance of either Table or\n    Paragraph. *parent* would most commonly be a reference to a main\n    Document object, but also works for a _Cell object, which itself can\n    contain paragraphs and tables.\n\n    Arguments:\n        parent: The main Word document object, or an individual `_Cell` object.\n\n    Yields:\n        A Paragraph or Table object.\n    \"\"\"\n    parent_elm = __get_parent_element(parent)\n    for child in parent_elm.iterchildren():\n        if isinstance(child, CT_P):\n            yield Paragraph(child, parent)\n        elif isinstance(child, CT_Tbl):\n            yield Table(child, parent)\n</code></pre>"},{"location":"reference/docx2audio/#docx2audio.main","title":"<code>main()</code>","text":"<p>main function</p> Source code in <code>docx2audio.py</code> <pre><code>def main():\n    \"\"\"main function\"\"\"\n    in_file_path, out_file_path, language = input_tool.get_sys_input(os.path.dirname(__file__))\n    chapters = []\n    chapters_path: List[str] = []\n    title_list:List[str] = []\n\n    m4b.init(BACK_END_TTS)\n\n    document = Document(in_file_path)\n    chapters = extract_chapters(document)\n    for idref, chapter in enumerate(chapters):\n        output_mp3_path   = f\"{in_file_path}.c{idref}.mp3\"\n        text_chapther, title = get_text_from_chapter(chapter)\n        title_list.append(title)\n        logger.info(\"idref %s\", idref)\n        with open(f\"{in_file_path}.c{idref}.txt\", \"w\", encoding=\"UTF-16\") as out_debug_file:\n            out_debug_file.write(text_chapther)\n        if m4b.generate_audio(text_chapther, output_mp3_path,\n                              lang=language, backend=BACK_END_TTS):\n            chapters_path.append(output_mp3_path)\n    metadata_output = ffmetadata_generator.generate_ffmetadata(chapters_path,\n                                                               chapter_titles=title_list)\n    m4b.generate_m4b(out_file_path, chapters_path, metadata_output)\n    m4b.close_edge_tts()\n</code></pre>"},{"location":"reference/ebook2audio/","title":"ebook2audio","text":"<p>This page describes the functions in the <code>ebook2audio</code> script.</p>"},{"location":"reference/ebook2audio/#ebook2audio","title":"<code>ebook2audio</code>","text":"<p>file: ebook2audio.py</p> <p>description: Convert your epub file to audiobook in MP3 format.</p> Usage example <p><code>python ebook2audio.py book.epub</code></p>"},{"location":"reference/ebook2audio/#ebook2audio.extract_by_epub","title":"<code>extract_by_epub(epub_path, directory_to_extract_path)</code>","text":"<p>Unzip the epub file and extract all in a temp directory.</p> <p>Parameters:</p> <ul> <li> <code>epub_path</code>               (<code>str</code>)           \u2013            <p>The path to the epub file.</p> </li> <li> <code>directory_to_extract_path</code>               (<code>str</code>)           \u2013            <p>The temp directory to extract epub file to.</p> </li> </ul> Source code in <code>ebook2audio.py</code> <pre><code>def extract_by_epub(epub_path:str, directory_to_extract_path:str) -&gt; None:\n    \"\"\"Unzip the epub file and extract all in a temp directory.\n\n    Arguments:\n        epub_path: The path to the epub file.\n        directory_to_extract_path: The temp directory to extract epub file to.\n    \"\"\"\n    logger.debug(\"Extracting input to temp directory %s.\", directory_to_extract_path)\n    with zipfile.ZipFile(epub_path, 'r') as zip_ref:\n        zip_ref.extractall(directory_to_extract_path)\n</code></pre>"},{"location":"reference/ebook2audio/#ebook2audio.extract_chapter_and_generate_mp3","title":"<code>extract_chapter_and_generate_mp3(tree, output_file_path, mp3_temp_dir, content_file_dir_path, guide, language)</code>","text":"<p>Extract id reference from container.xml file and extract chapter text.</p> <p>Parameters:</p> <ul> <li> <code>tree</code>               (<code>_ElementTree</code>)           \u2013            <p>The base of the XML tree in epub contents.</p> </li> <li> <code>output_file_path</code>               (<code>str</code>)           \u2013            <p>The path to save the result MP3 file.</p> </li> <li> <code>mp3_temp_dir</code>               (<code>str</code>)           \u2013            <p>The temporary directory path to save MP3 files as the XML tree is parsed.</p> </li> <li> <code>content_file_dir_path</code>               (<code>str</code>)           \u2013            <p>The path to the XML file.</p> </li> <li> <code>guide</code>               (<code>Dict[str, str]</code>)           \u2013            <p>A map of the guide XML node types and their hyperlink content.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>A list of the saved MP3 file paths.</p> </li> </ul> Source code in <code>ebook2audio.py</code> <pre><code>def extract_chapter_and_generate_mp3(tree:etree._ElementTree,  #pylint: disable=R0913,R0917\n                                     output_file_path:str,\n                                     mp3_temp_dir:str,\n                                     content_file_dir_path:str,\n                                     guide:Dict[str,str],\n                                     language:str) -&gt; List[str]:\n    \"\"\"Extract id reference from container.xml file and extract chapter text.\n\n    Arguments:\n        tree: The base of the XML tree in epub contents.\n        output_file_path: The path to save the result MP3 file.\n        mp3_temp_dir: The temporary directory path to save MP3 files as the XML tree is parsed.\n        content_file_dir_path: The path to the XML file.\n        guide: A map of the guide XML node types and their hyperlink content.\n\n    Returns:\n        A list of the saved MP3 file paths.\n    \"\"\"\n    chapters = []\n    for idref in tree.xpath(\"//*[local-name()='package']\"\n                            \"/*[local-name()='spine']\"\n                            \"/*[local-name()='itemref']\"\n                            \"/@idref\"):\n        output_debug_path= os.path.join(os.path.dirname(output_file_path),\n                                        f\"{mp3_temp_dir}/{idref}.log\")\n        output_mp3_path  = os.path.join(os.path.dirname(output_file_path),\n                                        f\"{mp3_temp_dir}/{idref}.mp3\")\n        text_chapther, _ = get_text_from_chapter(tree, idref,\n                                                content_file_dir_path,\n                                                guide)\n        logger.info(\"idref %s\", idref)\n        text_chapther = prepocess_text(text_chapther)\n        with open(output_debug_path, \"w\", encoding=\"UTF-16\") as out_debug_file:\n            out_debug_file.write(text_chapther)\n        if m4b.generate_audio(text_chapther, output_mp3_path,\n                              lang=language, backend=BACK_END_TTS):\n            chapters.append(output_mp3_path)\n    return chapters\n</code></pre>"},{"location":"reference/ebook2audio/#ebook2audio.get_guide_epub","title":"<code>get_guide_epub(root_tree)</code>","text":"<p>Get information about the guide information, described in content.opf file.</p> <p>Parameters:</p> <ul> <li> <code>root_tree</code>               (<code>ElementBase</code>)           \u2013            <p>The base of the XML tree in epub contents.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dict[str, str]</code>           \u2013            <p>A map of the guide XML node types and their hyperlink content.</p> </li> </ul> Source code in <code>ebook2audio.py</code> <pre><code>def get_guide_epub(root_tree: etree.ElementBase) -&gt; Dict[str,str]:\n    \"\"\"Get information about the guide information, described in content.opf file.\n\n    Arguments:\n        root_tree: The base of the XML tree in epub contents.\n\n    Returns:\n        A map of the guide XML node types and their hyperlink content.\n    \"\"\"\n    guide_res = {}\n    for reference in root_tree.xpath(\"//*[local-name()='package']\"\n                                \"/*[local-name()='guide']\"\n                                \"/*[local-name()='reference']\"):\n        guide_res[reference.attrib['type']] = reference.attrib['href']\n    return guide_res\n</code></pre>"},{"location":"reference/ebook2audio/#ebook2audio.get_metadata","title":"<code>get_metadata(root_tree)</code>","text":"<p>Extract basic metadata, as title, author and copyrights infos from content.opf.</p> <p>Parameters:</p> <ul> <li> <code>root_tree</code>               (<code>_ElementTree</code>)           \u2013            <p>The base of the XML tree in epub contents.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dict[str, str]</code>           \u2013            <p>A mapping of node titles and their vlaues from the root_tree.</p> </li> </ul> Source code in <code>ebook2audio.py</code> <pre><code>def get_metadata(root_tree:etree._ElementTree) -&gt; Dict[str,str]:\n    \"\"\"Extract basic metadata, as title, author and copyrights infos from content.opf.\n\n    Arguments:\n        root_tree: The base of the XML tree in epub contents.\n\n    Returns:\n        A mapping of node titles and their vlaues from the root_tree.\n    \"\"\"\n    metadata_leaf = root_tree.xpath(\"//*[local-name()='package']/*[local-name()='metadata']\")[0]\n    metadata_result = {\"title\":\"\", \"author\":\"\"}\n    namespace = metadata_leaf.nsmap\n    if None in namespace.keys():\n        del namespace[None]\n    title  = metadata_leaf.xpath(\"//dc:title\", namespaces=namespace)\n    if len(title)&gt;0:\n        metadata_result[\"title\"] = title[0].text\n    author = metadata_leaf.xpath(\"//dc:creator\", namespaces=namespace)\n    if len(author)&gt;0:\n        metadata_result[\"author\"] = author[0].text\n    rights = metadata_leaf.xpath(\"//dc:rights\", namespaces=namespace)\n    if len(rights)&gt;0:\n        metadata_result[\"copyright\"] = rights[0].text\n    descr = metadata_leaf.xpath(\"//dc:description\", namespaces=namespace)\n    if len(rights)&gt;0:\n        metadata_result[\"description\"] = descr[0].text\n    return metadata_result\n</code></pre>"},{"location":"reference/ebook2audio/#ebook2audio.get_text_from_chapter","title":"<code>get_text_from_chapter(root_tree, idref_ch, content_dir_path, guide_manifest)</code>","text":"<p>Starting from content.opf xml tree, extract chapter html path    and parse it to achieve the chapter.</p> <p>Parameters:</p> <ul> <li> <code>root_tree</code>               (<code>_ElementTree</code>)           \u2013            <p>The base of the XML tree in epub contents.</p> </li> <li> <code>idref_ch</code>               (<code>str</code>)           \u2013            <p>The XML ID of the chapter.</p> </li> <li> <code>content_dir_path</code>               (<code>str</code>)           \u2013            <p>The path to the XML file.</p> </li> <li> <code>guide_manifest</code>               (<code>Dict[str, str]</code>)           \u2013            <p>A map of the guide XML node types and their hyperlink content.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[str, Dict[str, str]]</code>           \u2013            <p>A tuple of the chapter's text and an empty dictionary.</p> </li> </ul> Source code in <code>ebook2audio.py</code> <pre><code>def get_text_from_chapter(root_tree:etree._ElementTree,\n                          idref_ch :str, content_dir_path:str,\n                          guide_manifest:Dict[str,str]) -&gt; Tuple[str, Dict[str,str]]:\n    \"\"\"Starting from content.opf xml tree, extract chapter html path\n       and parse it to achieve the chapter.\n\n    Arguments:\n        root_tree: The base of the XML tree in epub contents.\n        idref_ch: The XML ID of the chapter.\n        content_dir_path: The path to the XML file.\n        guide_manifest: A map of the guide XML node types and their hyperlink content.\n\n    Returns:\n        A tuple of the chapter's text and an empty dictionary.\n    \"\"\"\n    text_result = \"\"\n    for href in root_tree.xpath( f\"//*[local-name()='package']\"\n                            f\"/*[local-name()='manifest']\"\n                            f\"/*[local-name()='item'][@id='{idref_ch}']\"\n                            f\"/@href\"):\n        if href in guide_manifest.values():\n            #Skip the chapter used as guide\n            logging.debug(\"skipping %s\", href)\n            continue\n        xhtml_file_path = os.path.join(content_dir_path, href)\n        subtree = etree.parse(xhtml_file_path, etree.HTMLParser())\n        for ptag in subtree.xpath(\"//html/body/*\"):\n            for text in ptag.itertext():\n                text_result += text\n            text_result += \"\\n\"\n    return text_result, {}\n</code></pre>"},{"location":"reference/ebook2audio/#ebook2audio.main","title":"<code>main()</code>","text":"<p>main function</p> Source code in <code>ebook2audio.py</code> <pre><code>def main():\n    \"\"\"main function\"\"\"\n    in_file_path, out_file_path, language = input_tool.get_sys_input(os.path.dirname(__file__))\n    chapters = []\n\n    m4b.init(BACK_END_TTS)\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        extract_by_epub(in_file_path, tmp_dir)\n        logger.info(\"Parsing 'container.xml' file.\")\n        container_file_path=os.path.join(tmp_dir, \"META-INF/container.xml\")\n        tree = etree.parse(container_file_path)\n        for root_file_path in tree.xpath( \"//*[local-name()='container']\"\n                                        \"/*[local-name()='rootfiles']\"\n                                        \"/*[local-name()='rootfile']\"\n                                        \"/@full-path\"):\n            logger.info(\"Parsing '%s' file.\", root_file_path)\n            content_file_path = os.path.join(tmp_dir, root_file_path)\n            content_file_dir_path = os.path.dirname(content_file_path)\n            tree = etree.parse(content_file_path)\n            guide = get_guide_epub(tree)\n            metadata_book_output = get_metadata(tree)\n            logger.info(\"Parsed '%s' file.\", root_file_path)\n            with tempfile.TemporaryDirectory() as mp3_temp_dir:\n                chapters += extract_chapter_and_generate_mp3(tree,\n                                                             out_file_path,\n                                                             mp3_temp_dir,\n                                                             content_file_dir_path,\n                                                             guide,\n                                                             language)\n                metadata_output = ffmetadata_generator.generate_ffmetadata(chapters,\n                                                            title=metadata_book_output[\"title\"],\n                                                            author=metadata_book_output[\"author\"])\n                m4b.generate_m4b(out_file_path, chapters, metadata_output)\n</code></pre>"},{"location":"reference/ebook2audio/#ebook2audio.prepocess_text","title":"<code>prepocess_text(text_in)</code>","text":"<p>Remove possibly non-audible characters.</p> <p>Parameters:</p> <ul> <li> <code>text_in</code>               (<code>str</code>)           \u2013            <p>The epub file's text.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The processed epub file's text.</p> </li> </ul> Source code in <code>ebook2audio.py</code> <pre><code>def prepocess_text(text_in:str) -&gt; str:\n    \"\"\"Remove possibly non-audible characters.\n\n    Arguments:\n        text_in: The epub file's text.\n\n    Returns:\n        The processed epub file's text.\n    \"\"\"\n    text_out = codecs.decode(bytes(text_in, encoding=\"utf-8\"), encoding=\"utf-8\")\n    text_out = text_out.replace('\\xa0', '')\n    text_out = text_out.replace('\\r\\n\\t', '')\n    text_out = text_out.replace('\\r\\n', '\\n')\n    return text_out.strip()\n</code></pre>"},{"location":"reference/frontend/","title":"frontend","text":"<p>This page describes the functions in the <code>frontend</code> module.</p>"},{"location":"reference/frontend/#frontend.input_tool","title":"<code>frontend.input_tool</code>","text":"<p>file: input_file.py description: handling of external input</p>"},{"location":"reference/frontend/#frontend.input_tool.get_sys_input","title":"<code>get_sys_input(main_path, format_output='m4b')</code>","text":"<p>Get input and output path files.</p> <p>Parameters:</p> <ul> <li> <code>main_path</code>               (<code>str</code>)           \u2013            <p>The path of the calling script.</p> </li> <li> <code>format_output</code>               (<code>str</code>, default:                   <code>'m4b'</code> )           \u2013            <p>The format to save the result file as.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A tuple of the file supplied by the user at the </p> </li> <li> <code>str</code>           \u2013            <p>command-line and the path the result file is saved to.</p> </li> </ul> Source code in <code>frontend/input_tool.py</code> <pre><code>def get_sys_input(main_path:str, format_output:str=\"m4b\") -&gt; Tuple[str, str]:\n    \"\"\"Get input and output path files.\n\n    Arguments:\n        main_path: The path of the calling script.\n        format_output: The format to save the result file as.\n\n    Returns:\n        A tuple of the file supplied by the user at the \n        command-line and the path the result file is saved to.\n    \"\"\"\n    if len(sys.argv) != 3:\n        logger.error(\"Usage: %s &lt;input.docx&gt; &lt;language&gt;\",sys.argv[0])\n        sys.exit(1)\n    input_file_path  = sys.argv[1]\n    language         = sys.argv[2]\n    output_file_name = Path(input_file_path).stem\n    output_file_path = os.path.join(main_path,\n                                    output_file_name) + f\".{format_output}\"\n    assert language in SUPPORTED_LANGUAGE\n    return input_file_path, output_file_path, language\n</code></pre>"},{"location":"reference/pptx2audio/","title":"pptx2audio","text":"<p>This page describes the functions in the <code>pptx2audio</code> script.</p>"},{"location":"reference/pptx2audio/#pptx2audio","title":"<code>pptx2audio</code>","text":"<p>file: pptx2audio.py</p> <p>description: Convert your pptx to audiobook in MP3 format.</p> Usage example <p><code>python pptx2audio.py presentation.pptx</code></p>"},{"location":"reference/pptx2audio/#pptx2audio.extract_pptx_text","title":"<code>extract_pptx_text(path_pptx, language='it')</code>","text":"<p>Extract the text from each slide and concat. Arguments:     path_pptx (str): pptx presentation path Returns:     str: all text generated by presentation</p> Source code in <code>pptx2audio.py</code> <pre><code>def extract_pptx_text(path_pptx:str,\n                      language:str=\"it\") -&gt; str:\n    \"\"\"Extract the text from each slide and concat.\n    Arguments:\n        path_pptx (str): pptx presentation path\n    Returns:\n        str: all text generated by presentation\n    \"\"\"\n    text_out:str = \"\"\n    p: presentation.Presentation = pptx.Presentation(path_pptx)\n    for idx,s in enumerate(p.slides):\n        text_out += f\"\\n{TOK_NUM_SLIDES[language]} {idx}\\n\"\n        ts = __extract_text_from_slide(s)\n        text_out += ts\n        if len(ts) == 0:\n            text_out += \"\"\n    return text_out\n</code></pre>"},{"location":"reference/pptx2audio/#pptx2audio.main","title":"<code>main()</code>","text":"<p>main function</p> Source code in <code>pptx2audio.py</code> <pre><code>def main():\n    \"\"\"main function\"\"\"\n    input_file_path, out_file_path, language = input_tool.get_sys_input(os.path.dirname(__file__))\n    m4b.init(BACK_END_TTS)\n    text=extract_pptx_text(input_file_path)\n    m4b.generate_audio(text, out_file_path, lang=language, backend=BACK_END_TTS)\n</code></pre>"},{"location":"reference/pptx2audio/#pptx2audio.save_image_from_pptx","title":"<code>save_image_from_pptx(image, folder_path)</code>","text":"<p>Save an image to disk. Arguments:     image: The image to save.    folder_path: the directory where we want save the image.</p> Source code in <code>pptx2audio.py</code> <pre><code>def save_image_from_pptx(image:pptx.parts.image.Image, folder_path:str) -&gt; None:\n    \"\"\"Save an image to disk.\n    Arguments:\n        image: The image to save.\n       folder_path: the directory where we want save the image.\n    \"\"\"\n    filename = f\"{folder_path}/{image.filename}.{image.ext}\"\n    with open(filename, 'wb') as f:\n        f.write(image.blob)\n</code></pre>"},{"location":"reference/txt2audio/","title":"txt2audio","text":"<p>This page describes the functions in the <code>txt2audio</code> script.</p>"},{"location":"reference/txt2audio/#txt2audio","title":"<code>txt2audio</code>","text":"<p>file: txt2audio.py</p> <p>description: Convert your txt (UTF-8) to audiobook in MP3 format.</p> Usage example <p><code>python txt2audio.py document.txt</code></p>"},{"location":"reference/txt2audio/#txt2audio.main","title":"<code>main()</code>","text":"<p>main function</p> Source code in <code>txt2audio.py</code> <pre><code>def main():\n    \"\"\"main function\"\"\"\n    _, output_file_path, language = input_tool.get_sys_input(os.path.dirname(__file__),\n                                                   format_output=\"mp3\")\n    text:str = \"\"\n    with open(sys.argv[1], \"r\", encoding=\"UTF-8\") as file:\n        text = ''.join(file.readlines())\n\n    m4b.init(BACK_END_TTS)\n    if BACK_END_TTS == \"PYTTS\":\n        m4b.generate_audio_pytts(text, output_file_path, lang=language)\n    else:\n        loop = asyncio.get_event_loop_policy().get_event_loop()\n        try:\n            voices = loop.run_until_complete(m4b.get_voices_edge_tts(lang=language))\n            voice = voices[0][\"Name\"]\n            loop.run_until_complete(m4b.generate_audio_edge_tts(text, output_file_path,\n                                                                lang=\"it-IT\", voice=voice))\n        finally:\n            loop.close()\n</code></pre>"},{"location":"user-guide/","title":"User Guide","text":"<p>After you've completed the quick start guide, see this section for more information about each script.</p>"},{"location":"user-guide/docx-to-audio/","title":"Word documents","text":"<p>This page explains how to use the <code>docx2audio.py</code> script to convert Word documents to MP3 files.</p> <p>Important</p> <p>Word documents you want to convert must meet these requirements:</p> <ul> <li>The file extension must be .docx.</li> </ul>"},{"location":"user-guide/docx-to-audio/#run-the-script","title":"Run the script","text":"<p>To convert a Word document to MP3 files:</p> <ol> <li>Download the script and install the required libraries.</li> <li> <p>In your terminal, go to the Write2Audiobook project's root directory.</p> <pre><code>cd write2audiobook\n</code></pre> </li> <li> <p>Run the <code>docx2audio.py</code> script.</p> <pre><code>python3 docx2audio.py path/to/file/test.docx\n</code></pre> </li> </ol>"},{"location":"user-guide/docx-to-audio/#view-the-output","title":"View the output","text":"<p>The script creates MP3 files and plain text files as it converts the Word document. It may convert larger documents into multiple MP3 files and text files.</p> <p>For example, if the script creates X files:</p> <ul> <li>MP3 files will have a name like <code>\\&lt;original-file-name\\&gt;.docx.cX.mp3</code>.</li> <li>Text files will have a name like <code>\\&lt;original-file-name\\&gt;.docx.cX.txt</code></li> </ul> <p>Look for the MP3 files in the Word document's directory to confirm the conversion was successful.</p> <p></p>"},{"location":"user-guide/download-scripts/","title":"Download the scripts","text":"<p>This page explains how to download and update the Write2Audiobook scripts.</p>"},{"location":"user-guide/download-scripts/#download-the-scripts","title":"Download the scripts","text":"<p>Download the scripts from the Write2Audiobook GitHub repository.</p> <pre><code>git clone https://github.com/deangelisdf/write2audiobook\n</code></pre>"},{"location":"user-guide/download-scripts/#update-the-scripts","title":"Update the scripts","text":"<p>Update the scripts by pulling the latest version from the Write2Audiobook GitHub repository.</p> <pre><code>git pull\n</code></pre>"},{"location":"user-guide/ebook-to-audio/","title":"Ebooks","text":"<p>This page explains how to use the <code>ebook2audio.py</code> script to convert Ebooks to MP3 files.</p> <p>Important</p> <p>Ebooks you want to convert must meet these requirements:</p> <ul> <li>The file extension must be .pub.</li> </ul>"},{"location":"user-guide/ebook-to-audio/#run-the-script","title":"Run the script","text":"<p>To convert an Ebook to MP3 files:</p> <ol> <li>Download the script and install the required libraries.</li> <li> <p>In your terminal, go to the Write2Audiobook project's root directory.</p> <pre><code>cd write2audiobook\n</code></pre> </li> <li> <p>Run the <code>ebook2audio.py</code> script.</p> <pre><code>python3 ebook2audio.py path/to/file/test.epub\n</code></pre> </li> </ol>"},{"location":"user-guide/ebook-to-audio/#view-the-output","title":"View the output","text":"<p>The script creates MP3 files and plain text files as it converts the Ebook. It may convert larger books into multiple MP3 files and text files.</p> <p>For example, if the script creates X files:</p> <ul> <li>MP3 files will have a name like <code>itemX.mp3</code>.</li> <li>Text files will have a name like <code>itemX.log</code></li> </ul> <p>Look for the MP3 files in the Ebook's directory to confirm the conversion was successful.</p> <p></p>"},{"location":"user-guide/install-libraries/","title":"Install libraries","text":"<p>This page explains how to install the libraries and packages required to run the Write2Audiobook scripts.</p>"},{"location":"user-guide/install-libraries/#prerequisites","title":"Prerequisites","text":"<p>All Write2Audiobook scripts are written in Python. If you don't already have Python installed on your computer, see the Python Beginner's Guide for instructions on downloading and installing Python.</p>"},{"location":"user-guide/install-libraries/#virtual-environments","title":"Virtual environments","text":"<p>Virtual environments keep workspaces clean and avoid potential conflicts with previously install libraries. This keeps your development environments isolated. If something happens to a library in a virtual environment, you've contained the damage to that one folder.</p>"},{"location":"user-guide/install-libraries/#create-a-virtual-environment","title":"Create a virtual environment","text":"<p>Create a virtual environment for your Write2Audiobook project:</p> <ol> <li> <p>In your terminal, go to the Write2Audiobook project's root directory.</p> <pre><code>cd write2audiobook\n</code></pre> </li> <li> <p>Run the following command:</p> <pre><code>python3 -m venv .venv\n</code></pre> <p>This creates a virtual environment in new folder called <code>.venv</code>.</p> </li> </ol>"},{"location":"user-guide/install-libraries/#activate-a-virtual-environment","title":"Activate a virtual environment","text":"<p>Run the following code to activate a virtual environment:</p> PowershellCommand PromptLinux or macOS <pre><code>.venv\\Scripts\\Activate.ps1\n</code></pre> <pre><code>.venv\\Scripts\\activate.bat\n</code></pre> <pre><code>source .venv/bin/activate\n</code></pre> <p>When your virtual environment is active, you'll see <code>(.venv)</code> in front of your terminal's prompt.</p> <p></p>"},{"location":"user-guide/install-libraries/#exit-a-virtual-environment","title":"Exit a virtual environment","text":"<p>After you have finished working in the Write2Audiobook project, exit the virtual environment with the following command:</p> <pre><code>deactivate\n</code></pre>"},{"location":"user-guide/install-libraries/#install-the-required-libraries","title":"Install the required libraries","text":"<p>The Write2Audio project requires several Python libraries to run its scripts. The <code>requirements</code> file lists these libraries.</p> <p>Install the libraries from the <code>requirements</code> file:</p> <ol> <li>Activate your virtual environment.</li> <li> <p>Run the following command:</p> <pre><code>python3 -m pip install -r requirements\n</code></pre> </li> <li> <p>Confirm the installation succeeded by looking at the list of installed libraries.</p> <pre><code>python3 -m pip list\n</code></pre> </li> </ol> <p>You'll get a confirmation message when the installation is complete.</p> <p>Important</p> <p>If you're on a Linux system, you must install additional system packages. Install these packages with the following command: <pre><code>sudo apt update &amp;&amp; sudo apt install espeak ffmpeg libespeak1 -y\n</code></pre></p>"},{"location":"user-guide/pptx-to-audio/","title":"PowerPoint presentations","text":"<p>This page explains how to use the <code>pptx2audio.py</code> script to convert PowerPoint presentations to MP3 files.</p> <p>Important</p> <p>PowerPoint presentations you want to convert must meet these requirements:</p> <ul> <li>The file extension must be .pptx.</li> </ul>"},{"location":"user-guide/pptx-to-audio/#run-the-script","title":"Run the script","text":"<p>To convert a PowerPoint presentation to an m4b file:</p> <ol> <li>Download the script and install the required libraries.</li> <li> <p>In your terminal, go to the Write2Audiobook project's root directory.</p> <pre><code>cd write2audiobook\n</code></pre> </li> <li> <p>Run the <code>pptx2audio.py</code> script.</p> <pre><code>python3 pptx2audio.py path/to/file/test.pptx\n</code></pre> </li> </ol>"},{"location":"user-guide/pptx-to-audio/#view-the-output","title":"View the output","text":"<p>Look for the mb4 file in your current directory to confirm the conversion was successful.</p> <p></p>"},{"location":"user-guide/text-to-audio/","title":"Text files","text":"<p>This page explains how to use the <code>txt2audio.py</code> script to convert plain text files to MP3 files.</p> <p>Important</p> <p>Text files you want to convert must meet these requirements:</p> <ul> <li>The file encoding must be UTF-8.</li> <li>The file extension must be .txt.</li> </ul>"},{"location":"user-guide/text-to-audio/#run-the-script","title":"Run the script","text":"<p>To convert a TXT file to an MP3 file:</p> <ol> <li>Download the script and then install the required libraries.</li> <li> <p>In your terminal, go to the Write2Audiobook project's root directory.</p> <pre><code>cd write2audiobook\n</code></pre> </li> <li> <p>Run the <code>txt2audio.py</code> script.</p> <pre><code>python3 txt2audio.py path/to/file/test.txt\n</code></pre> </li> </ol>"},{"location":"user-guide/text-to-audio/#view-the-output","title":"View the output","text":"<p>Look for the MP3 file in your current directory to confirm the conversion was successful.</p> <p></p>"}]}